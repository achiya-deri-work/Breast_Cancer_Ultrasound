{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import one_hot, accuracy, randint_distinct, augmant_data\n",
    "from models import BaseCNNClassifier, ResNet18, ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.random.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a composition of transformations for data augmentation\n",
    "transforms = v2.Compose([\n",
    "    # Convert image to PIL Image format\n",
    "    v2.ToPILImage(),\n",
    "    # Randomly flip the image horizontally with 50% probability\n",
    "    v2.RandomHorizontalFlip(0.5),\n",
    "    # Randomly rotate the image by up to 45 degrees\n",
    "    v2.RandomRotation(45),\n",
    "    # Convert image to tensor format\n",
    "    v2.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for file names and image size\n",
    "files_names = ['benign', 'malignant', 'normal']\n",
    "image_sz = 224\n",
    "\n",
    "# Initialize empty tensors for X and y\n",
    "X = torch.tensor([], dtype=torch.float32)\n",
    "y = torch.tensor([], dtype=torch.int16)\n",
    "\n",
    "def collect_training_data(X, y):\n",
    "    \"\"\"\n",
    "    Collect training data from files in the current directory.\n",
    "\n",
    "    Args:\n",
    "        X (torch.tensor): Empty tensor to store image data\n",
    "        y (torch.tensor): Empty tensor to store class labels\n",
    "\n",
    "    Returns:\n",
    "        X (torch.tensor): Tensor with image data\n",
    "        y (torch.tensor): Tensor with class labels\n",
    "    \"\"\"\n",
    "    for file in files_names:\n",
    "        # Construct path to file and get class number\n",
    "        path = os.path.join(os.getcwd().replace('\\\\', '/'), file)\n",
    "        class_num = files_names.index(file)\n",
    "        print(f\"Class: {file} | Class value: {class_num}\")\n",
    "\n",
    "        # Iterate over images in the file\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            # Skip images with \"mask\" in the name\n",
    "            if \"mask\" not in img:\n",
    "                # Read image and resize to image_sz\n",
    "                img_array = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE)\n",
    "                new_array = cv.resize(img_array, (image_sz, image_sz))\n",
    "\n",
    "                # Append image data to X and class label to y\n",
    "                X = torch.cat((X, torch.tensor(new_array, dtype=torch.float32).unsqueeze(0)), dim=0)\n",
    "                y = torch.cat((y, torch.tensor([class_num], dtype=torch.int16).unsqueeze(0)), dim=0)\n",
    "\n",
    "    # Normalize image data and add channel dimension\n",
    "    X = X / 256\n",
    "    X = X.unsqueeze(1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Call the function to collect training data\n",
    "X, y = collect_training_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the data\n",
    "X_temp, y_temp = augmant_data(X_train, y_train, transforms, 3)\n",
    "X_train, y_train = torch.cat((X_temp, X_train), dim=0), torch.cat((y_temp, y_train), dim=0)\n",
    "del X_temp, y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN model\n",
    "model_0 = BaseCNNClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_0 = torch.optim.AdamW(model_0.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Get random batches of data and one hot encode the labels\n",
    "    batch_idxs = randint_distinct(0, X_train.size(0), batch_size)\n",
    "    X_batch, y_batch = X_train[batch_idxs], y_train[batch_idxs]\n",
    "    y_batch = one_hot(y_batch).to(device)\n",
    "\n",
    "    # Forward pass, compute loss, compute accuracy\n",
    "    y_pred = model_0(X_batch)\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    train_acc = accuracy(y_pred, y_batch)\n",
    "\n",
    "    # Compute backpropagation and optimization\n",
    "    optimizer_0.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_0.step()\n",
    "\n",
    "    # Evaluate the model on a test set every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model_0.eval()\n",
    "        with torch.inference_mode():\n",
    "            # Get random batches of data and one hot encode the labels\n",
    "            batch_idxs = randint_distinct(0, X_test.size(0), X_test.size(0))\n",
    "            X_batch, y_batch = X_test[batch_idxs], y_test[batch_idxs]\n",
    "            y_batch = one_hot(y_batch).to(device)\n",
    "\n",
    "            # Forward pass, compute loss, compute accuracy\n",
    "            test_logits = model_0(X_batch)\n",
    "            test_loss = loss_fn(test_logits, y_batch)\n",
    "            test_acc = accuracy(test_logits, y_batch)\n",
    "\n",
    "        model_0.train()\n",
    "\n",
    "        # Print the loss and accuracy\n",
    "        print(f\"Epoch: {epoch+1} | Train loss: {loss.item():.4f} | Train Acc: {train_acc.item():.4f} | Test loss: {test_loss.item():.4f} | Test Acc: {test_acc.item():.4f}\\n\")\n",
    "\n",
    "        # Save the model if the test accuracy is higher than 0.8 and higher than the previous best accuracy\n",
    "        if test_acc.item() > 0.8 and test_acc.item() > model_0.best_acc:\n",
    "            # Get current model accuracy and index\n",
    "            model_0.best_acc = test_acc.item()\n",
    "            idxs = [int(file.split(\"Idx\")[1][:-4]) for file in os.listdir(os.getcwd().replace('\\\\', '/') + \"/saves\") if \"Idx\" in file]\n",
    "            idx = max(idxs) + 1 if idxs else 0\n",
    "            \n",
    "            # Save the model\n",
    "            torch.save(model_0.state_dict(), os.getcwd().replace('\\\\', '/') + f\"/saves/BaseCNNAcc{test_acc.item():.5f}Idx{idx}.pth\")\n",
    "            print(f\"Model saved successfully with accuracy: {test_acc.item():.4f}\")\n",
    "\n",
    "# Print the best accuracy\n",
    "print(f\"Best Accuracy: {model_0.best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet18 model\n",
    "model_1 = ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Get random batches of data and one hot encode the labels\n",
    "    batch_idxs = randint_distinct(0, X_train.size(0), batch_size)\n",
    "    X_batch, y_batch = X_train[batch_idxs], y_train[batch_idxs]\n",
    "    y_batch = one_hot(y_batch).to(device)\n",
    "\n",
    "    # Forward pass, compute loss, compute accuracy\n",
    "    y_pred = model_1(X_batch)\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    train_acc = accuracy(y_pred, y_batch)\n",
    "\n",
    "    # Compute backpropagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate the model on a test set every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model_1.eval()\n",
    "        with torch.inference_mode():\n",
    "            # Get random batches of data and one hot encode the labels\n",
    "            batch_idxs = randint_distinct(0, X_test.size(0), X_test.size(0))\n",
    "            X_batch, y_batch = X_test[batch_idxs], y_test[batch_idxs]\n",
    "            y_batch = one_hot(y_batch).to(device)\n",
    "\n",
    "            # Forward pass, compute loss, compute accuracy\n",
    "            test_logits = model_1(X_batch)\n",
    "            test_loss = loss_fn(test_logits, y_batch)\n",
    "            test_acc = accuracy(test_logits, y_batch)\n",
    "        \n",
    "        model_1.train()\n",
    "\n",
    "        # Print the loss and accuracy\n",
    "        print(f\"Epoch: {epoch+1} | Train loss: {loss.item():.4f} | Train Acc: {train_acc.item():.4f} | Test loss: {test_loss.item():.4f} | Test Acc: {test_acc.item():.4f}\\n\")\n",
    "\n",
    "        # Save the model if the test accuracy is higher than 0.8 and higher than the previous best accuracy\n",
    "        if test_acc.item() > 0.8 and test_acc.item() > model_1.best_acc:\n",
    "            # Get current model accuracy and index\n",
    "            model_1.best_acc = test_acc.item()\n",
    "            idxs = [int(file.split(\"Idx\")[1][:-4]) for file in os.listdir(os.getcwd().replace('\\\\', '/') + \"/saves\") if \"Idx\" in file]\n",
    "            idx = max(idxs) + 1 if idxs else 0\n",
    "            \n",
    "            # Save the model\n",
    "            torch.save(model_1.state_dict(), os.getcwd().replace('\\\\', '/') + f\"/saves/ResNet18Acc{test_acc.item():.5f}Idx{idx}.pth\")\n",
    "            print(f\"Model saved successfully with accuracy: {test_acc.item():.4f}\")\n",
    "\n",
    "# Print the best accuracy\n",
    "print(f\"Best accuracy: {model_1.best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet34 model\n",
    "model_2 = ResNet34().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Get random batches of data and one hot encode the labels\n",
    "    batch_idxs = randint_distinct(0, X_train.size(0), batch_size)\n",
    "    X_batch, y_batch = X_train[batch_idxs], y_train[batch_idxs]\n",
    "    y_batch = one_hot(y_batch).to(device)\n",
    "\n",
    "    # Forward pass, compute loss, compute accuracy\n",
    "    y_pred = model_2(X_batch)\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    train_acc = accuracy(y_pred, y_batch)\n",
    "\n",
    "    # Compute backpropagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate the model on a test set every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model_2.eval()\n",
    "        with torch.inference_mode():\n",
    "            # Get random batches of data and one hot encode the labels\n",
    "            batch_idxs = randint_distinct(0, X_test.size(0), X_test.size(0))\n",
    "            X_batch, y_batch = X_test[batch_idxs], y_test[batch_idxs]\n",
    "            y_batch = one_hot(y_batch).to(device)\n",
    "\n",
    "            # Forward pass, compute loss, compute accuracy\n",
    "            test_logits = model_2(X_batch)\n",
    "            test_loss = loss_fn(test_logits, y_batch)\n",
    "            test_acc = accuracy(test_logits, y_batch)\n",
    "        \n",
    "        model_2.train()\n",
    "\n",
    "        # Print the loss and accuracy\n",
    "        print(f\"Epoch: {epoch+1} | Train loss: {loss.item():.4f} | Train Acc: {train_acc.item():.4f} | Test loss: {test_loss.item():.4f} | Test Acc: {test_acc.item():.4f}\\n\")\n",
    "\n",
    "        # Save the model if the test accuracy is higher than 0.8 and higher than the previous best accuracy\n",
    "        if test_acc.item() > 0.8 and test_acc.item() > model_2.best_acc:\n",
    "            # Get current model accuracy and index\n",
    "            model_2.best_acc = test_acc.item()\n",
    "            idxs = [int(file.split(\"Idx\")[1][:-4]) for file in os.listdir(os.getcwd().replace('\\\\', '/') + \"/saves\") if \"Idx\" in file]\n",
    "            idx = max(idxs) + 1 if idxs else 0\n",
    "\n",
    "            # Save the model\n",
    "            torch.save(model_2.state_dict(), os.getcwd().replace('\\\\', '/') + f\"/saves/ResNet34Acc{test_acc.item():.5f}Idx{idx}.pth\")\n",
    "            print(f\"Model saved successfully with accuracy: {test_acc.item():.4f}\")\n",
    "\n",
    "# Print the best accuracy\n",
    "print(f\"Best accuracy: {model_2.best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean inaffective models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = os.listdir(os.getcwd().replace('\\\\', '/') + \"/saves\")\n",
    "accs = [acc.split(\"Acc\")[1] for acc in [path.split(\"Idx\")[0] for path in paths]]\n",
    "for i in range(len(accs)):\n",
    "    if float(accs[i]) < 0.82:\n",
    "        os.remove(os.getcwd().replace('\\\\', '/') + \"/saves/\" + paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = os.listdir(os.getcwd().replace('\\\\', '/') + \"/saves\")\n",
    "accs = [acc.split(\"Acc\")[1] for acc in [path.split(\"Idx\")[0] for path in paths]]\n",
    "for i in range(len(accs)):\n",
    "    if float(accs[i]) < 0.86 and \"ResNet18\" in paths[i]:\n",
    "        os.remove(os.getcwd().replace('\\\\', '/') + \"/saves/\" + paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = os.listdir(os.getcwd().replace('\\\\', '/') + \"/saves\")\n",
    "accs = [acc.split(\"Acc\")[1] for acc in [path.split(\"Idx\")[0] for path in paths]]\n",
    "for i in range(len(accs)):\n",
    "    if float(accs[i]) < 0.84 and \"ResNet34\" in paths[i]:\n",
    "        os.remove(os.getcwd().replace('\\\\', '/') + \"/saves/\" + paths[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
